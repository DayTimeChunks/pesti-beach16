# No Event counts the number of hours without a major discharge (i.e. 18 m3/h)
noEventVect <- grpAlteck$numNoEvent
aux <- split(noEventVect, cumsum(noEventVect == 0))
v <- unlist(sapply(aux, cumsum))
grpAlteck$noEventHrs <- v/60 # Convert to Hrs
# No rain counts for Hrs without at least 0.2 mm rain (in a 2 minute interval)
grpAlteck$numNoRain <- ifelse(grpAlteck$Rain.mm < 0.2, 1, 0)
grpAlteck$numNoRain <- ifelse(is.na(grpAlteck$numNoRain), 1, grpAlteck$numNoRain)
sum(is.na(grpAlteck$numNoRain))
noRainVect <- grpAlteck$numNoRain
aux2 <- split(noRainVect, cumsum(noRainVect == 0))
v2 <- unlist(sapply(aux2, cumsum))
grpAlteck$dryhrs <- v2/60
#length(grpAlteck$numNoEvent)
#length(noEventVect)
#grpAlteck$minSinceEvent <- NA
#cumDuration <- 0
# if Q.HW1 < 10m3h: cumDuration += 3 min
# else cumDuration = 0
# for every cell in Date, assign cumDuration to timeSinceEvent
#for (i in 1:length(grpAlteck$Date)) {
#  if (grpAlteck[i,]['Q.HW1'] < 17){
#    grpAlteck[i,]['minSinceEvent'] = cumDuration
#    cumDuration <- cumDuration + 3.0
#  } else {
#    cumDuration <- 0
#    grpAlteck[i,]['minSinceEvent'] = cumDuration
#  }
#}
# (Sub)Event markers
ggplot() +
geom_line(data = grpAlteck, aes(x= Date, y = Q.HW1), color = "blue") +
geom_point(data = grpAlteck, aes(x= Date, y = Markers), color = "forestgreen") +
scale_y_continuous(trans=log_trans(), breaks=c(1,5,8, 10,25, 50, 80, 100,1000))
ggplot() +
geom_line(data = grpAlteck, aes(x= Date, y = dryhrs), color = "blue")
View(grpAlteck)
write.csv2(grpAlteck, "Data/groupAlteck2016_R.csv", row.names = F)
Sys.setlocale("LC_ALL", "English")
library("stringr")
library("plyr")
library("dplyr")
library("zoo")
library("ggplot2")
library("plotly")
# setwd("D:/Documents/these_pablo/Alteckendorf2016/R")
# setwd("/Users/DayTightChunks/Documents/PhD/Routput/Alteck/R")
# setwd("D:/Documents/these_pablo/Alteckendorf2016/00_TransparencyFolder")
getwd()
source("global.R")
weeklyhydro = read.csv2("Data/WeeklyHydro_R.csv", header = TRUE)
colnames(weeklyhydro)[colnames(weeklyhydro) == "ID"] <- "WeekSubWeek"
head(weeklyhydro)
weeklyflux = read.csv2("Data/fluxAlteck2016_R.csv", header = TRUE)
head(weeklyflux)
outletConc = read.csv2("Data/OutletConc_W0toW17.csv", sep = ",", dec =".", header = T)
outletConc$ID4 <- as.character(outletConc$ID4)
outletConc <- outletConc[outletConc$ID4 != "J+7", ]
outletConc$Vol.SPE.L <- outletConc$Vol.SPE.mL/1000
outletConc <- outletConc[,c("WeekSubWeek", "Conc.mug.L", "Conc.SD", "Vol.SPE.L", "Conc.in500uL")]
head(outletConc)
filters = read.csv2("Data/MESAlteckWater.csv")
filters$MO.mg.L = ifelse(filters$MO.mg.L < 0, 0.0001, filters$MO.mg.L)
head(filters)
# MESA/MOXA data cleaning
outletESAOXA = read.csv2("Data/Outlet_ESAOXA_W0toW17.csv", header = T)
outletESAOXA$ID <- as.character(outletESAOXA$ID)
split <- strsplit(outletESAOXA$ID, "-", fixed = TRUE)
outletESAOXA$ESAOXA_SD <- sapply(split, "[", 4)
split_vor <- strsplit(outletESAOXA$ID, "-SD", fixed = TRUE)
outletESAOXA$ESAOXA_Mean <- sapply(split_vor, "[", 1)
means_temp <- subset(outletESAOXA, is.na(outletESAOXA$ESAOXA_SD))
sd_temp <- subset(outletESAOXA, !is.na(outletESAOXA$ESAOXA_SD))
means_temp$ID <- NULL
sd_temp$ID <- NULL
head(sd_temp)
head(means_temp)
outletESAOXA <- merge(means_temp, sd_temp, by = "ESAOXA_Mean", all = T)
outletESAOXA$ESAOXA_SD.x <- NULL
outletESAOXA$ESAOXA_SD.y <- NULL
split_ID <- strsplit(outletESAOXA$ESAOXA_Mean, "A0-", fixed = T)
outletESAOXA$ID <- sapply(split_ID, "[", 2)
outletESAOXA$ESAOXA_Mean <- NULL
outletESAOXA <- outletESAOXA[ , c("ID", "MOXA.ugL.x", "MOXA.ugL.y", "MESA.ugL.x", "MESA.ugL.y")]
colnames(outletESAOXA) <- c("WeekSubWeek", "OXA_mean", "OXA_SD", "ESA_mean",  "ESA_SD")
outletESAOXA$WeekSubWeek <- as.factor(outletESAOXA$WeekSubWeek)
head(outletESAOXA)
# Outlet isotope data:
outletIso = read.csv2("Data/Outlet_Isotopes_W0toW17.csv", header = T, dec = ".")
if (length(outletIso) == 1){
outletIso = read.csv("Data/Outlet_Isotopes_W0toW17.csv", header = T)
}
str(outletIso)
colnames(outletIso)
# Correct for extraction shift
outletIso$d.13C.12C = round( (outletIso$d.13C.12C - meanshift_w), 1)
outletIso$DD13 <- outletIso$d.13C.12C - initialDelta
# Filter isotope data:
filtersIso = read.csv2("Data/MESAlteck_FilterIsotopes.csv", header = T, dec = ".")
#filtersIso <- filtersIso[filtersIso$Levl != "J+7", ]
if (length(filtersIso) == 1){
filtersIso = read.csv("Data/MESAlteck_FilterIsotopes.csv", header = T)
}
colnames(filtersIso)
filtersIso$WeekSubWeek = paste(filtersIso$Week, filtersIso$Num, sep = "-")
colnames(filtersIso)[colnames(filtersIso) == "DD13.32.253."] <- "DD13"
colnames(filtersIso)[colnames(filtersIso) == "ng..C."] <- "ngC"
str(filtersIso)
hydroChem = read.csv2("Data/AO-Hydrochem.csv", header = T)
hydroChem = hydroChem[, c("WeekSubWeek",
"NH4.mM",
"TIC.ppm.filt",
"Cl.mM",
"NO3...mM",
"PO4..mM",
"NPOC.ppm" ,
"TIC.ppm.unfilt",
"TOC.ppm.unfilt" )]
head(hydroChem)
outletIso <- outletIso[complete.cases(outletIso[ , "d.13C.12C"]), ]
isoOutSummary = ddply(outletIso, c("WeekSubWeek"), summarise,
N    = length(d.13C.12C),
diss.d13C = mean(d.13C.12C),
SD.d13C = sd(d.13C.12C),
# se.d13C = SD.d13C / sqrt(N),
N_d13C.diss = length(d.13C.12C))
isoFiltSummary = ddply(filtersIso, c("WeekSubWeek"), summarise,
N    = length(d.13C.12C),
filt.d13C = mean(d.13C.12C),
filt.SD.d13C = sd(d.13C.12C) #,
# filt.se.d13C = filt.SD.d13C / sqrt(N),
# N_ngC.fl = length(ngC),
# ngC.mean.fl = mean(ngC),
# ngC.SD.fl = sd(ngC)
)
head(isoFiltSummary)
View(outletIso)
View(outletConc)
# Dissolved
out.CoIs = merge(outletConc,  outletESAOXA, by = "WeekSubWeek", all = T)
out.CoIs = merge(out.CoIs, isoOutSummary, by = "WeekSubWeek", all = T)
# Filters (MES, Conc.MES)
out.CoIs = merge(out.CoIs, filters, by = "WeekSubWeek", all = T)
out.CoIs = merge(out.CoIs, isoFiltSummary, by= "WeekSubWeek", all = T)
# Remaining fraction
out.CoIs$DD13C.diss <- (out.CoIs$diss.d13C - (d13Co))
out.CoIs$DD13C.filt <- (out.CoIs$filt.d13C - (d13Co))
# Discharge times
out.CoIs = merge(weeklyhydro, out.CoIs, by = "WeekSubWeek", all = T)
# Discharge summary
out.CoIs = merge(weeklyflux, out.CoIs, by = "WeekSubWeek", all = T)
out.CoIs$tf <- as.POSIXct(out.CoIs$tf, "%Y-%m-%d %H:%M", tz = "EST")
out.CoIs$ti <- as.POSIXct(out.CoIs$ti, "%Y-%m-%d %H:%M", tz = "EST")
class(out.CoIs$tf)
sum(is.na(out.CoIs$tf))
View(out.CoIs)
Sys.setlocale("LC_ALL", "English")
library("stringr")
library("plyr")
library("dplyr")
library("zoo")
library("ggplot2")
library("plotly")
# setwd("D:/Documents/these_pablo/Alteckendorf2016/R")
# setwd("/Users/DayTightChunks/Documents/PhD/Routput/Alteck/R")
# setwd("D:/Documents/these_pablo/Alteckendorf2016/00_TransparencyFolder")
getwd()
source("global.R")
weeklyhydro = read.csv2("Data/WeeklyHydro_R.csv", header = TRUE)
colnames(weeklyhydro)[colnames(weeklyhydro) == "ID"] <- "WeekSubWeek"
head(weeklyhydro)
weeklyflux = read.csv2("Data/fluxAlteck2016_R.csv", header = TRUE)
head(weeklyflux)
outletConc = read.csv2("Data/OutletConc_W0toW17.csv", sep = ",", dec =".", header = T)
outletConc$ID4 <- as.character(outletConc$ID4)
outletConc <- outletConc[outletConc$ID4 != "J+7", ]
outletConc$Vol.SPE.L <- outletConc$Vol.SPE.mL/1000
outletConc <- outletConc[,c("WeekSubWeek", "Conc.mug.L", "Conc.SD", "Vol.SPE.L", "Conc.in500uL")]
head(outletConc)
filters = read.csv2("Data/MESAlteckWater.csv")
filters$MO.mg.L = ifelse(filters$MO.mg.L < 0, 0.0001, filters$MO.mg.L)
head(filters)
# MESA/MOXA data cleaning
outletESAOXA = read.csv2("Data/Outlet_ESAOXA_W0toW17.csv", header = T)
outletESAOXA$ID <- as.character(outletESAOXA$ID)
split <- strsplit(outletESAOXA$ID, "-", fixed = TRUE)
outletESAOXA$ESAOXA_SD <- sapply(split, "[", 4)
split_vor <- strsplit(outletESAOXA$ID, "-SD", fixed = TRUE)
outletESAOXA$ESAOXA_Mean <- sapply(split_vor, "[", 1)
means_temp <- subset(outletESAOXA, is.na(outletESAOXA$ESAOXA_SD))
sd_temp <- subset(outletESAOXA, !is.na(outletESAOXA$ESAOXA_SD))
means_temp$ID <- NULL
sd_temp$ID <- NULL
head(sd_temp)
head(means_temp)
outletESAOXA <- merge(means_temp, sd_temp, by = "ESAOXA_Mean", all = T)
outletESAOXA$ESAOXA_SD.x <- NULL
outletESAOXA$ESAOXA_SD.y <- NULL
split_ID <- strsplit(outletESAOXA$ESAOXA_Mean, "A0-", fixed = T)
outletESAOXA$ID <- sapply(split_ID, "[", 2)
outletESAOXA$ESAOXA_Mean <- NULL
outletESAOXA <- outletESAOXA[ , c("ID", "MOXA.ugL.x", "MOXA.ugL.y", "MESA.ugL.x", "MESA.ugL.y")]
colnames(outletESAOXA) <- c("WeekSubWeek", "OXA_mean", "OXA_SD", "ESA_mean",  "ESA_SD")
outletESAOXA$WeekSubWeek <- as.factor(outletESAOXA$WeekSubWeek)
head(outletESAOXA)
# Outlet isotope data:
outletIso = read.csv2("Data/Outlet_Isotopes_W0toW17.csv", header = T, dec = ".")
if (length(outletIso) == 1){
outletIso = read.csv("Data/Outlet_Isotopes_W0toW17.csv", header = T)
}
str(outletIso)
colnames(outletIso)
# Correct for extraction shift
outletIso$d.13C.12C = round( (outletIso$d.13C.12C - meanshift_w), 1)
outletIso$DD13 <- outletIso$d.13C.12C - initialDelta
# Filter isotope data:
filtersIso = read.csv2("Data/MESAlteck_FilterIsotopes.csv", header = T, dec = ".")
#filtersIso <- filtersIso[filtersIso$Levl != "J+7", ]
if (length(filtersIso) == 1){
filtersIso = read.csv("Data/MESAlteck_FilterIsotopes.csv", header = T)
}
colnames(filtersIso)
filtersIso$WeekSubWeek = paste(filtersIso$Week, filtersIso$Num, sep = "-")
colnames(filtersIso)[colnames(filtersIso) == "DD13.32.253."] <- "DD13"
colnames(filtersIso)[colnames(filtersIso) == "ng..C."] <- "ngC"
str(filtersIso)
hydroChem = read.csv2("Data/AO-Hydrochem.csv", header = T)
hydroChem = hydroChem[, c("WeekSubWeek",
"NH4.mM",
"TIC.ppm.filt",
"Cl.mM",
"NO3...mM",
"PO4..mM",
"NPOC.ppm" ,
"TIC.ppm.unfilt",
"TOC.ppm.unfilt" )]
head(hydroChem)
outletIso <- outletIso[complete.cases(outletIso[ , "d.13C.12C"]), ]
isoOutSummary = ddply(outletIso, c("WeekSubWeek"), summarise,
N    = length(d.13C.12C),
diss.d13C = mean(d.13C.12C),
SD.d13C = sd(d.13C.12C),
# se.d13C = SD.d13C / sqrt(N),
N_d13C.diss = length(d.13C.12C))
isoFiltSummary = ddply(filtersIso, c("WeekSubWeek"), summarise,
N    = length(d.13C.12C),
filt.d13C = mean(d.13C.12C),
filt.SD.d13C = sd(d.13C.12C) #,
# filt.se.d13C = filt.SD.d13C / sqrt(N),
# N_ngC.fl = length(ngC),
# ngC.mean.fl = mean(ngC),
# ngC.SD.fl = sd(ngC)
)
head(isoFiltSummary)
# Dissolved
out.CoIs = merge(outletConc,  outletESAOXA, by = "WeekSubWeek", all = T)
out.CoIs = merge(out.CoIs, isoOutSummary, by = "WeekSubWeek", all = T)
# Filters (MES, Conc.MES)
out.CoIs = merge(out.CoIs, filters, by = "WeekSubWeek", all = T)
out.CoIs = merge(out.CoIs, isoFiltSummary, by= "WeekSubWeek", all = T)
# Remaining fraction
out.CoIs$DD13C.diss <- (out.CoIs$diss.d13C - (d13Co))
out.CoIs$DD13C.filt <- (out.CoIs$filt.d13C - (d13Co))
# Discharge times
out.CoIs = merge(weeklyhydro, out.CoIs, by = "WeekSubWeek", all = T)
# Discharge summary
out.CoIs = merge(weeklyflux, out.CoIs, by = "WeekSubWeek", all = T)
out.CoIs$tf <- as.POSIXct(out.CoIs$tf, "%Y-%m-%d %H:%M", tz = "EST")
out.CoIs$ti <- as.POSIXct(out.CoIs$ti, "%Y-%m-%d %H:%M", tz = "EST")
class(out.CoIs$tf)
sum(is.na(out.CoIs$tf))
write.csv(out.CoIs, "Data/MarkerResponse_R05.csv", row.names = F)
# Temprarily remove Weeks 16 & 17 (need to get discharge data)
# No discharge data yet avaialble to multiply against...
out.CoIs <- out.CoIs[!is.na(out.CoIs$tf), ]
# V[m3] * MES [mg/L] * 1000 [L/m3] * [1 Kg/10^6 mg]
out.CoIs$ExpMES.Kg = out.CoIs$Volume.m3*out.CoIs$MES.mg.L/1000
# Assume first index is equivalent to second for all measured values
# (i.e. needed for na.approx operation below)
out.CoIs[1, c("Conc.mug.L")] <- out.CoIs[2, c("Conc.mug.L")]
out.CoIs[1, c("Conc.SD")] <- out.CoIs[2, c("Conc.SD")]
out.CoIs[1, c("Vol.SPE.L")] <- out.CoIs[2, c("Vol.SPE.L")]
out.CoIs[1, c("OXA_mean")] <- out.CoIs[2, c("OXA_mean")]
out.CoIs[1, c("OXA_SD")] <- out.CoIs[2, c("OXA_SD")]
out.CoIs[1, c("ESA_mean")] <- out.CoIs[2, c("ESA_mean")]
out.CoIs[1, c("ESA_SD")] <- out.CoIs[2, c("ESA_SD")]
out.CoIs[1, c("Conc.Solids.mug.gMES")] <- out.CoIs[2, c("Conc.Solids.mug.gMES")]
out.CoIs[1, c("Conc.Solids.ug.gMES.SD")] <- out.CoIs[2, c("Conc.Solids.ug.gMES.SD")]
out.CoIs[1, c("ExpMES.Kg")] <- out.CoIs[2, c("ExpMES.Kg")]
# Assign linear approximation of trailing and leading observed values
out.CoIs <- out.CoIs[with(out.CoIs , order(ti)), ]
out.CoIs$Conc.mug.L <- na.approx(out.CoIs$Conc.mug.L)
out.CoIs$Volume.m3[nrow(out.CoIs)]
val = out.CoIs$Volume.m3[nrow(out.CoIs)]
val
is.na(val)
out.CoIs = out.CoIs[1:nrow(out.CoIs)-1, ]
out.CoIs$Conc.mug.L <- na.approx(out.CoIs$Conc.mug.L)
out.CoIs$Conc.SD <- na.approx(out.CoIs$Conc.SD)
mark = read.csv2(file.path(path, "Data/MarkerResponse_R05.csv"))
View(mark)
mark = read.csv(file.path(path, "Data/MarkerResponse_R05.csv"))
View(q)
q = read.csv2(file.path(path, "Data/groupAlteck2016_R.csv"))
View(q)
names(q)
q = q[ , c("Date", "DateCheck.S", "DateCheck", "Q.HW1", "DayMoYr", "Vol2min", "sampleQ", "Type", "SubWeeks", "Weeks", "WeekNo" )]
q = q[ , c("Date", "DateCheck", "Q.HW1", "DayMoYr", "Vol2min", "sampleQ", "Type", "SubWeeks", "Weeks", "WeekNo" )]
names(mark)
mark = mark[, c("WeekSubWeek", "AveDischarge.m3.h", "Volume.m3",  "Sampled.Hrs", "Sampled", "Conc.mug.L" , "Conc.SD",
"Vol.SPE.L", "Conc.in500uL", "OXA_mean", "OXA_SD", "ESA_mean", "ESA_SD", "N.x", "diss.d13C", "SD.d13C",
"N_d13C.diss", "MES.mg.L", "MES.sd", "MO.mg.L", "Conc.Solids.mug.gMES", "Conc.Solids.ug.gMES.SD", "N.y",
"filt.d13C",  "filt.SD.d13C", "DD13C.diss", "DD13C.filt" )]
names(mark)
mark = mark[, c("WeekSubWeek", "AveDischarge.m3.h", "Volume.m3",  "Sampled.Hrs", "Sampled", "Conc.mug.L" , "Conc.SD",
"Vol.SPE.L", "Conc.in500uL", "OXA_mean", "OXA_SD", "ESA_mean", "ESA_SD", "N.x", "diss.d13C", "SD.d13C",
"MES.mg.L", "MES.sd", "MO.mg.L", "Conc.Solids.mug.gMES", "Conc.Solids.ug.gMES.SD", "N.y",
"filt.d13C",  "filt.SD.d13C", "DD13C.diss", "DD13C.filt" )]
names(mark)
mark = mark[, c("WeekSubWeek",
# "AveDischarge.m3.h", "Volume.m3",  "Sampled.Hrs",
"Sampled", "Conc.mug.L" , "Conc.SD",
"Vol.SPE.L", "Conc.in500uL", "OXA_mean", "OXA_SD", "ESA_mean", "ESA_SD", "N.x", "diss.d13C", "SD.d13C",
"MES.mg.L", "MES.sd", "MO.mg.L", "Conc.Solids.mug.gMES", "Conc.Solids.ug.gMES.SD", "N.y",
"filt.d13C",  "filt.SD.d13C", "DD13C.diss", "DD13C.filt" )]
names(mark)
mark = mark[, c("WeekSubWeek",
# "AveDischarge.m3.h", "Volume.m3",  "Sampled.Hrs",
"Sampled",
"Conc.mug.L" , "Conc.SD",
# "Vol.SPE.L", "Conc.in500uL",
"OXA_mean", "OXA_SD", "ESA_mean", "ESA_SD",
"N.x", "diss.d13C", "SD.d13C",
"MES.mg.L", "MES.sd", "MO.mg.L", "Conc.Solids.mug.gMES", "Conc.Solids.ug.gMES.SD",
"N.y",  "filt.d13C",  "filt.SD.d13C" #,
#"DD13C.diss", "DD13C.filt"
)]
mark$WeekSubWeek[nrow(mark)-1]
mark$WeekSubWeek[nrow(mark)-1]
mark$WeekSubWeek[nrow(mark)-1] == as.factor("W6-3j7")
mark$WeekSubWeek[nrow(mark)-1] == as.character("W6-3j7")
mark = mark[mark$WeekSubWeek != as.character("W6-3j7")]
mark = mark[mark$WeekSubWeek != as.character("W6-3j7"), ]
mark = mark[mark$WeekSubWeek != as.character("W6-3j7") & !is.na(mark$WeekSubWeek), ]
mark = mark[, c("WeekSubWeek",
# "AveDischarge.m3.h", "Volume.m3",  "Sampled.Hrs",
# "Sampled",
"Conc.mug.L" , "Conc.SD",
# "Vol.SPE.L", "Conc.in500uL",
"OXA_mean", "OXA_SD", "ESA_mean", "ESA_SD",
"N.x", "diss.d13C", "SD.d13C",
"MES.mg.L", "MES.sd", "MO.mg.L", "Conc.Solids.mug.gMES", "Conc.Solids.ug.gMES.SD",
"N.y",  "filt.d13C",  "filt.SD.d13C" #,
#"DD13C.diss", "DD13C.filt"
)]
q$Date = as.POSIXct(strptime(q$DateCheck, "%d/%m/%Y %H:%M", tz="EST"))
q$DayMoYr = as.POSIXct(strptime(q$DateCheck, "%d/%m/%Y", tz="EST"))
sum(is.na(q$Date))
naDates = q[is.na(q$Date == TRUE),]
duplicateAlteck <- q[duplicated(q$DateCheck),]
head(duplicateAlteck)
catchment_area
Sys.setlocale("LC_ALL", "English")
MAC = F
WIN = T
if (MAC) {
if (WIN){
path = file.path("C:/Users/DayTimeChunks/Documents/PhD/HydrologicalMonitoring")
} else {
path = file.path("/Users/DayTightChunks/Documents/PhD/HydrologicalMonitoring")
}
} else {
path = file.path("D:/Documents/these_pablo/Alteckendorf2016/HydrologicalMonitoring")
}
source(file.path(path, "global.R"))
# Plotting functions
library("scales")
library("tidyr")
library("dplyr")
library("reshape")
library("zoo") # na.approx()
# setwd("D:/Documents/these_pablo/Alteckendorf2016/R")
# MAC
# setwd("/Users/DayTightChunks/Documents/PhD/Routput/Alteck/R")
# Mac-WIN
# setwd("C:/Users/DayTightChunks/Documents/Models/pesti-beach16/Analysis/Data")
getwd()
q = read.csv2(file.path(path, "Data/groupAlteck2016_R.csv"))
q$Vol.L = q$Vol2min * 1000
q = q[ , c("Date", "DateCheck", "Q.HW1", "DayMoYr", "Vol.L", "sampleQ", "Type", "SubWeeks", "Weeks", "WeekNo" )]
names(q)
mark = read.csv(file.path(path, "Data/MarkerResponse_R05.csv"))
mark = mark[, c("WeekSubWeek",
# "AveDischarge.m3.h", "Volume.m3",  "Sampled.Hrs",
# "Sampled",
"Conc.mug.L" , "Conc.SD",
# "Vol.SPE.L", "Conc.in500uL",
"OXA_mean", "OXA_SD", "ESA_mean", "ESA_SD",
"N.x", "diss.d13C", "SD.d13C",
"MES.mg.L", "MES.sd", "MO.mg.L", "Conc.Solids.mug.gMES", "Conc.Solids.ug.gMES.SD" #,
#"N.y",  "filt.d13C",  "filt.SD.d13C" #,
#"DD13C.diss", "DD13C.filt"
)]
names(mark)
# Delete repeated W6 observation, or with NA in week markers
# mark = mark[mark$WeekSubWeek != as.character("W6-3j7") & !is.na(mark$WeekSubWeek), ]
q$Date = as.POSIXct(strptime(q$DateCheck, "%d/%m/%Y %H:%M", tz="EST"))
q$DayMoYr = as.POSIXct(strptime(q$DateCheck, "%d/%m/%Y", tz="EST"))
CHECKO = F
if (CHECKO){
sum(is.na(q$Date))
naDates = q[is.na(q$Date == TRUE),]
duplicateAlteck <- q[duplicated(q$DateCheck),]
head(duplicateAlteck)
}
qm = merge(q, mark, by.x = "SubWeeks", by.y = "WeekSubWeek", all = T)
# Dissolved
qm$SmetOut_ug.obs = qm$Vol.L*qm$Conc.mug.L
qm$SmetOut_ug.sd = qm$Vol.L*qm$Conc.SD
qm$OxaOut_ug.obs =  qm$Vol.L*qm$OXA_mean
qm$OxaOut_ug.sd =  qm$Vol.L*qm$OXA_SD
qm$EsaOut_ug.obs =  qm$Vol.L*qm$ESA_mean
qm$EsaOut_ug.sd =  qm$Vol.L*qm$ESA_SD
# Suspended Solids (SS)
# Smet.ug in SS = ug/g * (MES [mg/L] * [1g/10^3mg])  * Vol [L]
qm$SmetSS_ug.obs = qm$Conc.Solids.mug.gMES * (qm$MES.mg.L*1/10^3)  * qm$Vol.L
qm$SmetSS_ug.sd = qm$Conc.Solids.ug.gMES.SD * (qm$MES.sd*1/10^3)  * qm$Vol.L
qm$MassDelta.obs = qm$SmetOut_ug.obs*qm$diss.d13C
qm$MassDelta.sd = qm$SmetOut_ug.sd*qm$SD.d13C
names(qm)
# Step 1
qmDay <- qm %>%
group_by(DayMoYr, SubWeeks) %>%
dplyr::summarize(Volday.L = sum(Vol.L),
SmOut_ug.obs = sum(SmetOut_ug.obs),
SmOut_ug.sd = (sum(SmetOut_ug.sd^2))^0.5, # Cumulative SD
OxOut_ug.obs = sum(OxaOut_ug.obs),
OxOut_ug.sd = (sum(OxaOut_ug.sd^2))^0.5, # Cumulative SD
EsOut_ug.obs = sum(EsaOut_ug.obs),
EsOut_ug.sd = (sum(EsaOut_ug.sd^2))^0.5, # Cumulative SD
ConcSmOut_ugL.obs = SmOut_ug.obs/Volday.L, # Smet
ConcSmOut_ugL.sd = SmOut_ug.sd/Volday.L,
ConcOxOut_ugL.obs = OxOut_ug.obs/Volday.L, # Oxa
ConcOxOut_ugL.sd = OxOut_ug.sd/Volday.L,
ConcEsOut_ugL.obs = EsOut_ug.obs/Volday.L, # Esa
ConcEsOut_ugL.sd = EsOut_ug.sd/Volday.L,
delta.obs = sum(MassDelta.obs)/(sum(SmetOut_ug.obs)),
delta.sd = (sum(MassDelta.sd^2))^0.5/(sum(SmetOut_ug.sd^2))^0.5
)
# Step 2
# Get all duplicated days
allDup = qmDay %>%
group_by(DayMoYr) %>%
filter(n()>1)
# Assume same delta on the same day
deltasDup = allDup %>%
group_by(DayMoYr) %>%
dplyr::summarize(delta.obs = mean(delta.obs, na.rm = T),
delta.sd = mean(delta.sd, na.rm = T))
deltasDup$delta.obs = ifelse(deltasDup$delta.obs == "NaN", NA, deltasDup$delta.obs)
deltasDup$delta.sd = ifelse(deltasDup$delta.sd == "NaN", NA, deltasDup$delta.sd)
# Delete delta columns on allDup
cols = ncol(allDup)-2
allDup = allDup[, c(1:cols)]
# Invert 1st two rows for na.approx
allDup = allDup[c(2,1:nrow(allDup)), ]
allDup$ConcSmOut_ugL.obs = na.approx(allDup$ConcSmOut_ugL.obs)
allDup$ConcSmOut_ugL.sd = na.approx(allDup$ConcSmOut_ugL.sd)
allDup$ConcOxOut_ugL.obs= na.approx(allDup$ConcOxOut_ugL.obs)
allDup$ConcOxOut_ugL.sd = na.approx(allDup$ConcOxOut_ugL.sd)
allDup$ConcEsOut_ugL.obs = na.approx(allDup$ConcEsOut_ugL.obs)
allDup$ConcEsOut_ugL.sd = na.approx(allDup$ConcEsOut_ugL.sd)
allDup = merge(allDup, deltasDup, by = "DayMoYr", all = T)
ndup = qmDay %>%
group_by(DayMoYr) %>%
filter(n()==1)
qmDay = rbind.data.frame(ndup, allDup)
qmDay = qmDay[order(qmDay$DayMoYr), ]
# head(dupQm)
qmBlk = qmDay %>%
group_by(DayMoYr) %>%
dplyr::summarize(VolTot.L = sum(Volday.L),
ConSmOut_ugL.blk = sum(ConcSmOut_ugL.obs * Volday.L)/sum(Volday.L),
ConSmOut_ugL.sd = sum(ConcSmOut_ugL.sd * Volday.L)/sum(Volday.L),
ConOxOut_ugL.blk = sum(ConcOxOut_ugL.obs * Volday.L)/sum(Volday.L),
ConOxOut_ugL.sd = sum(ConcOxOut_ugL.sd * Volday.L)/sum(Volday.L),
ConEsOut_ugL.blk = sum(ConcEsOut_ugL.obs * Volday.L)/sum(Volday.L),
ConEsOut_ugL.sd = sum(ConcEsOut_ugL.sd * Volday.L)/sum(Volday.L),
deltaOut.blk = sum(delta.obs * Volday.L)/sum(Volday.L),
deltaOut.sd =  sum(delta.sd * Volday.L)/sum(Volday.L)
)
m <- q %>%
group_by(DayMoYr) %>%
dplyr::summarise(SubWeeks = SubWeeks[1])
qmBlk = merge(qmBlk, m, by = "DayMoYr")
write.csv(qmBlk, "qmBlk_R.csv", row.names = F) # , sep = ";", dec = ".")
View(qmBlk)
qmBlk$JDay = seq.int(177, nrow(qmBlk))
nrow(qmBlk)
qmBlk$JDay = seq.int(nrow(data)) + 177
qmBlk$JDay = seq.int(nrow(qmBlk)) + 177
qmBlk$JDay = seq.int(nrow(qmBlk)) + 176
write.csv(qmBlk, "qmBlk_R.csv", row.names = F) # , sep = ";", dec = ".")
qmBlk$time = seq.int(nrow(qmBlk))
qmBlk$VolTot.m3 = qmBlk$VolTot.L/10^3
Volm3_tss = qmBlk[,c("Jday", "VolTot.m3")]
Volm3_tss = qmBlk[,c("JDay", "VolTot.m3")]
write.table(Volm3_tss, "BEACH_R/Vol_m3day.tss", sep="\t", row.names = F)
qmBlk$VolTot.m3 = round(qmBlk$VolTot.L/10^3, 3)
Volm3_tss = qmBlk[,c("JDay", "VolTot.m3")]
write.table(Volm3_tss, "BEACH_R/Vol_m3day.tss", sep="\t", row.names = F)
mean(qmBlk$VolTot.m3)
