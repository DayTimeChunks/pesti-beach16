grpAlteck$SubWeeks[grpAlteck$Date >= as.POSIXct('2016-04-23 06:37:00' , tz="EST") &
grpAlteck$Date < as.POSIXct('2016-04-26 11:50:00' , tz="EST")] = as.character('W4-2x') # Not sampled
grpAlteck$SubWeeks[grpAlteck$Date >= as.POSIXct('2016-04-26 11:50:00' , tz="EST") &
grpAlteck$Date < as.POSIXct('2016-05-01 10:46:00' , tz="EST")] = as.character('W5-1')
grpAlteck$SubWeeks[grpAlteck$Date >= as.POSIXct('2016-05-01 10:46:00' , tz="EST") &
grpAlteck$Date < as.POSIXct('2016-05-03 12:02:00' , tz="EST")] = as.character('W5-2')
#
grpAlteck$SubWeeks[grpAlteck$Date >= as.POSIXct('2016-05-03 12:02:00' , tz="EST") &
grpAlteck$Date < as.POSIXct('2016-05-03 13:09:00' , tz="EST")] = as.character('W5-3x')
grpAlteck$SubWeeks[grpAlteck$Date >= as.POSIXct('2016-05-03 13:09:00' , tz="EST") &
grpAlteck$Date < as.POSIXct('2016-05-10 00:05:00' , tz="EST")] = as.character('W6-1')
grpAlteck$SubWeeks[grpAlteck$Date >= as.POSIXct('2016-05-10 00:05:00' , tz="EST") &
grpAlteck$Date < as.POSIXct('2016-05-12 06:33:00' , tz="EST")] = as.character('W6-2')
grpAlteck$SubWeeks[grpAlteck$Date >= as.POSIXct('2016-05-12 06:33:00' , tz="EST") &
grpAlteck$Date < as.POSIXct('2016-05-12 09:12:00' , tz="EST")] = as.character('W6-3')
grpAlteck$SubWeeks[grpAlteck$Date >= as.POSIXct('2016-05-12 09:12:00' , tz="EST") &
grpAlteck$Date < as.POSIXct('2016-05-12 12:52:00' , tz="EST")] = as.character('W6-4')
#
grpAlteck$SubWeeks[grpAlteck$Date >= as.POSIXct('2016-05-12 12:52:00' , tz="EST") &
grpAlteck$Date < as.POSIXct('2016-05-13 12:05:00' , tz="EST")] = as.character('W6-5x') # Not sampled
grpAlteck$SubWeeks[grpAlteck$Date >= as.POSIXct('2016-05-13 12:05:00' , tz="EST") &
grpAlteck$Date < as.POSIXct('2016-05-16 15:11:00' , tz="EST")] = as.character('W7-1')
#
grpAlteck$SubWeeks[grpAlteck$Date >= as.POSIXct('2016-05-16 15:11:00' , tz="EST") &
grpAlteck$Date < as.POSIXct('2016-05-17 09:16:00' , tz="EST")] = as.character('W7-2x') # Not sampled
grpAlteck$SubWeeks[grpAlteck$Date >= as.POSIXct('2016-05-17 09:16:00' , tz="EST") &
grpAlteck$Date < as.POSIXct('2016-05-23 18:02:00' , tz="EST")] = as.character('W8-1')
#
grpAlteck$SubWeeks[grpAlteck$Date >= as.POSIXct('2016-05-23 18:02:00' , tz="EST") &
grpAlteck$Date < as.POSIXct('2016-05-24 12:00:00' , tz="EST")] = as.character('W8-2x') # Not sampled
grpAlteck$SubWeeks[grpAlteck$Date >= as.POSIXct('2016-05-24 12:00:00' , tz="EST") &
grpAlteck$Date < as.POSIXct('2016-05-29 12:09:00' , tz="EST")] = as.character('W9-1')
grpAlteck$SubWeeks[grpAlteck$Date >= as.POSIXct('2016-05-29 12:09:00' , tz="EST") &
grpAlteck$Date < as.POSIXct('2016-05-30 05:48:00' , tz="EST")] = as.character('W9-2')
grpAlteck$SubWeeks[grpAlteck$Date >= as.POSIXct('2016-05-30 05:48:00' , tz="EST") &
grpAlteck$Date < as.POSIXct('2016-05-30 12:11:00' , tz="EST")] = as.character('W9-3')
grpAlteck$SubWeeks[grpAlteck$Date >= as.POSIXct('2016-05-30 12:11:00' , tz="EST") &
grpAlteck$Date < as.POSIXct('2016-05-30 17:28:00' , tz="EST")] = as.character('W9-4')
##
grpAlteck$SubWeeks[grpAlteck$Date >= as.POSIXct('2016-05-30 17:28:00' , tz="EST") &
grpAlteck$Date < as.POSIXct('2016-05-31 12:00:00' , tz="EST")] = as.character('W9-5x') # Not sampled
grpAlteck$SubWeeks[grpAlteck$Date >= as.POSIXct('2016-05-31 12:00:00' , tz="EST") &
grpAlteck$Date < as.POSIXct('2016-06-02 12:57:00' , tz="EST")] = as.character('W10-1')
grpAlteck$SubWeeks[grpAlteck$Date >= as.POSIXct('2016-06-02 12:57:00' , tz="EST") &
grpAlteck$Date < as.POSIXct('2016-06-03 12:05:00' , tz="EST")] = as.character('W10-2')
grpAlteck$SubWeeks[grpAlteck$Date >= as.POSIXct('2016-06-03 12:05:00' , tz="EST") &
grpAlteck$Date < as.POSIXct('2016-06-04 08:35:00' , tz="EST")] = as.character('W10-3')
grpAlteck$SubWeeks[grpAlteck$Date >= as.POSIXct('2016-06-04 08:35:00' , tz="EST") &
grpAlteck$Date < as.POSIXct('2016-06-04 11:00:00' , tz="EST")] = as.character('W10-4')
grpAlteck$SubWeeks[grpAlteck$Date >= as.POSIXct('2016-06-04 11:00:00' , tz="EST") &
grpAlteck$Date < as.POSIXct('2016-06-04 15:31:00' , tz="EST")] = as.character('W10-5')
#
grpAlteck$SubWeeks[grpAlteck$Date >= as.POSIXct('2016-06-04 15:31:00' , tz="EST") &
grpAlteck$Date < as.POSIXct('2016-06-07 12:00:00' , tz="EST")] = as.character('W10-6x') # Not sampled
grpAlteck$SubWeeks[grpAlteck$Date >= as.POSIXct('2016-06-07 12:00:00' , tz="EST") &
grpAlteck$Date < as.POSIXct('2016-06-10 05:25:00' , tz="EST")] = as.character('W11-1')
grpAlteck$SubWeeks[grpAlteck$Date >= as.POSIXct('2016-06-10 05:25:00' , tz="EST") &
grpAlteck$Date < as.POSIXct('2016-06-14 12:34:00' , tz="EST")] = as.character('W11-2')
grpAlteck$SubWeeks[grpAlteck$Date >= as.POSIXct('2016-06-14 12:34:00' , tz="EST") &
grpAlteck$Date < as.POSIXct('2016-06-14 13:06:00' , tz="EST")] = as.character('W11-3')
grpAlteck$SubWeeks[grpAlteck$Date >= as.POSIXct('2016-06-14 13:06:00' , tz="EST") &
grpAlteck$Date < as.POSIXct('2016-06-15 08:14:00' , tz="EST")] = as.character('W12-1')
grpAlteck$SubWeeks[grpAlteck$Date >= as.POSIXct('2016-06-15 08:14:00' , tz="EST") &
grpAlteck$Date < as.POSIXct('2016-06-16 08:21:00' , tz="EST")] = as.character('W12-2')
grpAlteck$SubWeeks[grpAlteck$Date >= as.POSIXct('2016-06-16 08:21:00' , tz="EST") &
grpAlteck$Date < as.POSIXct('2016-06-17 00:49:00' , tz="EST")] = as.character('W12-3')
grpAlteck$SubWeeks[grpAlteck$Date >= as.POSIXct('2016-06-17 00:49:00' , tz="EST") &
grpAlteck$Date < as.POSIXct('2016-06-17 11:05:00' , tz="EST")] = as.character('W12-4')
#
grpAlteck$SubWeeks[grpAlteck$Date >= as.POSIXct('2016-06-17 11:05:00' , tz="EST") &
grpAlteck$Date < as.POSIXct('2016-06-21 12:00:00' , tz="EST")] = as.character('W12-5x')# Not sampled
grpAlteck$SubWeeks[grpAlteck$Date >= as.POSIXct('2016-06-21 12:00:00' , tz="EST") &
grpAlteck$Date < as.POSIXct('2016-06-24 14:51:00' , tz="EST")] = as.character('W13-1')
grpAlteck$SubWeeks[grpAlteck$Date >= as.POSIXct('2016-06-24 14:51:00' , tz="EST") &
grpAlteck$Date < as.POSIXct('2016-06-25 07:49:00' , tz="EST")] = as.character('W13-2')
grpAlteck$SubWeeks[grpAlteck$Date >= as.POSIXct('2016-06-25 07:49:00' , tz="EST") &
grpAlteck$Date < as.POSIXct('2016-06-28 08:55:00' , tz="EST")] = as.character('W13-3')
grpAlteck$SubWeeks[grpAlteck$Date >= as.POSIXct('2016-06-28 08:55:00' , tz="EST") &
grpAlteck$Date < as.POSIXct('2016-07-04 14:41:00' , tz="EST")] = as.character('W14-1')
grpAlteck$SubWeeks[grpAlteck$Date >= as.POSIXct('2016-07-04 14:41:00', tz="EST") &
grpAlteck$Date <= as.POSIXct('2016-07-12 10:20:00', tz="EST")] = as.character('W15-1')
head(grpAlteck)
sum(is.na(grpAlteck$Q.m3Hrs))
sum(is.na(grpAlteck$SubWeeks))
sum(is.na(grpAlteck$Q.HW1))
Split <- strsplit(grpAlteck$SubWeeks, "-", fixed = TRUE)
grpAlteck$Weeks <- sapply(Split, "[", 1)
Split2 <- strsplit(grpAlteck$SubWeeks, "W", fixed = TRUE)
grpAlteck$WeekNo <- sapply(Split2, "[", 2)
Split3 <- strsplit(grpAlteck$WeekNo, "-", fixed=T)
grpAlteck$WeekNo <- sapply(Split3, "[", 1)
grpAlteck$WeekNo = as.numeric(grpAlteck$WeekNo)
head(grpAlteck)
library(plyr)
library(dplyr)
library(gridExtra)
library("scales")
detach("package:plyr", unload=TRUE)
Q1change <- mutate(grpAlteck, Row = 1:n()) %>%
mutate(PercentChange = (Q.HW1-lag(Q.HW1))/lag(Q.HW1) * 100)
Q1change$PercentChange[1] <- 0
dd <- Q1change[, c("Date", "Q.HW1")]
# set the number of rows to reduce by
idx <- ceiling(seq_len(nrow(Q1change)) / 10)
# do colMeans on the last column with lapply
# bind them with rbind to give a matrix, then convert to as.data.frame
res <- as.data.frame(do.call(rbind, lapply(split(dd[ncol(dd)], idx),
colMeans, na.rm = TRUE)))
# assign first value of "Date" in each n-th group to the new dataframe
res$Date <- dd$Date[seq(1, nrow(dd), by=10)]
# Compute the %change on every row
res1 <- mutate(res, Event = 1:n()) %>%
mutate(PercentChange = (Q.HW1-lag(Q.HW1))/lag(Q.HW1) * 100)
res1 <- mutate(res1, Event = 1:n()) %>%
mutate(Change = (Q.HW1-lag(Q.HW1)))
res1$PercentChange[1] <- 0
res1$Markers1 <- ifelse(  res1$Change > 5 , res1$Q.HW1, NA)
res1$Markers2 <- ifelse(  res1$PercentChange > 90 & res1$Q.HW1 >20 & res1$Q.HW1 < 100, res1$Q.HW1, NA)
res1$Markers <- ifelse(!is.na(res1$Markers1), res1$Markers1,
ifelse(!is.na(res1$Markers2), res1$Markers2, NA))
res <- res1[complete.cases(res1["Markers"]),]
resTime <- mutate(res, Event = 1:n()) %>%
mutate(TimeDiff = Date-lag(Date))
resTime$TimeDiff[1]<-1440
resTime <- resTime[resTime$TimeDiff > 20, ]
# For some reason, changed minutes to hrs
resTime <- mutate(resTime, Event = 1:n()) %>%
mutate(TimeDiff = Date-lag(Date))
# Add first row time, so as to not loose it
resTime$TimeDiff[1]<-24
resTime <- resTime[resTime$TimeDiff > 5, ]
resTime <- mutate(resTime, Event = 1:n()) %>%
mutate(TimeDiff = Date-lag(Date))
resTime$TimeDiff[1]<-24
resTime <- resTime[resTime$TimeDiff >= 9, ]
resTime <- mutate(resTime, Event = 1:n()) %>%
mutate(TimeDiff = Date-lag(Date))
resTime$TimeDiff[1]<-24
resTime <- resTime[resTime$TimeDiff > 12, ]
resTime <- mutate(resTime, Event = 1:n()) %>%
mutate(TimeDiff = Date-lag(Date))
resTime$TimeDiff[1]<-24
resTime$Markers1 <- NULL
resTime$Markers2 <- NULL
resTime$Q.HW1 <- NULL
grpAlteck <- merge(grpAlteck, resTime, by= "Date", all = T)
sum(is.na(grpAlteck$Q.HW1))
grpAlteck$numNoEvent <- ifelse(grpAlteck$Q.HW1 < 18, 1, 0)
grpAlteck$numNoEvent <- ifelse(is.na(grpAlteck$numNoEvent), 0, grpAlteck$numNoEvent)
sum(is.na(grpAlteck$numNoEvent))
# No Event counts the number of hours without a major discharge (i.e. 18 m3/h)
noEventVect <- grpAlteck$numNoEvent
aux <- split(noEventVect, cumsum(noEventVect == 0))
v <- unlist(sapply(aux, cumsum))
grpAlteck$noEventHrs <- v/60 # Convert to Hrs
# No rain counts for Hrs without at least 0.2 mm rain (in a 2 minute interval)
grpAlteck$numNoRain <- ifelse(grpAlteck$Rain.mm < 0.2, 1, 0)
grpAlteck$numNoRain <- ifelse(is.na(grpAlteck$numNoRain), 1, grpAlteck$numNoRain)
sum(is.na(grpAlteck$numNoRain))
noRainVect <- grpAlteck$numNoRain
aux2 <- split(noRainVect, cumsum(noRainVect == 0))
v2 <- unlist(sapply(aux2, cumsum))
grpAlteck$dryhrs <- v2/60
#length(grpAlteck$numNoEvent)
#length(noEventVect)
#grpAlteck$minSinceEvent <- NA
#cumDuration <- 0
# if Q.HW1 < 10m3h: cumDuration += 3 min
# else cumDuration = 0
# for every cell in Date, assign cumDuration to timeSinceEvent
#for (i in 1:length(grpAlteck$Date)) {
#  if (grpAlteck[i,]['Q.HW1'] < 17){
#    grpAlteck[i,]['minSinceEvent'] = cumDuration
#    cumDuration <- cumDuration + 3.0
#  } else {
#    cumDuration <- 0
#    grpAlteck[i,]['minSinceEvent'] = cumDuration
#  }
#}
# (Sub)Event markers
ggplot() +
geom_line(data = grpAlteck, aes(x= Date, y = Q.HW1), color = "blue") +
geom_point(data = grpAlteck, aes(x= Date, y = Markers), color = "forestgreen") +
scale_y_continuous(trans=log_trans(), breaks=c(1,5,8, 10,25, 50, 80, 100,1000))
ggplot() +
geom_line(data = grpAlteck, aes(x= Date, y = dryhrs), color = "blue")
View(grpAlteck)
write.csv2(grpAlteck, "Data/groupAlteck2016_R.csv", row.names = F)
Sys.setlocale("LC_ALL", "English")
library("stringr")
library("plyr")
library("dplyr")
library("zoo")
library("ggplot2")
library("plotly")
# setwd("D:/Documents/these_pablo/Alteckendorf2016/R")
# setwd("/Users/DayTightChunks/Documents/PhD/Routput/Alteck/R")
# setwd("D:/Documents/these_pablo/Alteckendorf2016/00_TransparencyFolder")
getwd()
source("global.R")
weeklyhydro = read.csv2("Data/WeeklyHydro_R.csv", header = TRUE)
colnames(weeklyhydro)[colnames(weeklyhydro) == "ID"] <- "WeekSubWeek"
head(weeklyhydro)
weeklyflux = read.csv2("Data/fluxAlteck2016_R.csv", header = TRUE)
head(weeklyflux)
outletConc = read.csv2("Data/OutletConc_W0toW17.csv", sep = ",", dec =".", header = T)
outletConc$ID4 <- as.character(outletConc$ID4)
outletConc <- outletConc[outletConc$ID4 != "J+7", ]
outletConc$Vol.SPE.L <- outletConc$Vol.SPE.mL/1000
outletConc <- outletConc[,c("WeekSubWeek", "Conc.mug.L", "Conc.SD", "Vol.SPE.L", "Conc.in500uL")]
head(outletConc)
filters = read.csv2("Data/MESAlteckWater.csv")
filters$MO.mg.L = ifelse(filters$MO.mg.L < 0, 0.0001, filters$MO.mg.L)
head(filters)
# MESA/MOXA data cleaning
outletESAOXA = read.csv2("Data/Outlet_ESAOXA_W0toW17.csv", header = T)
outletESAOXA$ID <- as.character(outletESAOXA$ID)
split <- strsplit(outletESAOXA$ID, "-", fixed = TRUE)
outletESAOXA$ESAOXA_SD <- sapply(split, "[", 4)
split_vor <- strsplit(outletESAOXA$ID, "-SD", fixed = TRUE)
outletESAOXA$ESAOXA_Mean <- sapply(split_vor, "[", 1)
means_temp <- subset(outletESAOXA, is.na(outletESAOXA$ESAOXA_SD))
sd_temp <- subset(outletESAOXA, !is.na(outletESAOXA$ESAOXA_SD))
means_temp$ID <- NULL
sd_temp$ID <- NULL
head(sd_temp)
head(means_temp)
outletESAOXA <- merge(means_temp, sd_temp, by = "ESAOXA_Mean", all = T)
outletESAOXA$ESAOXA_SD.x <- NULL
outletESAOXA$ESAOXA_SD.y <- NULL
split_ID <- strsplit(outletESAOXA$ESAOXA_Mean, "A0-", fixed = T)
outletESAOXA$ID <- sapply(split_ID, "[", 2)
outletESAOXA$ESAOXA_Mean <- NULL
outletESAOXA <- outletESAOXA[ , c("ID", "MOXA.ugL.x", "MOXA.ugL.y", "MESA.ugL.x", "MESA.ugL.y")]
colnames(outletESAOXA) <- c("WeekSubWeek", "OXA_mean", "OXA_SD", "ESA_mean",  "ESA_SD")
outletESAOXA$WeekSubWeek <- as.factor(outletESAOXA$WeekSubWeek)
head(outletESAOXA)
# Outlet isotope data:
outletIso = read.csv2("Data/Outlet_Isotopes_W0toW17.csv", header = T, dec = ".")
if (length(outletIso) == 1){
outletIso = read.csv("Data/Outlet_Isotopes_W0toW17.csv", header = T)
}
str(outletIso)
colnames(outletIso)
# Correct for extraction shift
outletIso$d.13C.12C = round( (outletIso$d.13C.12C - meanshift_w), 1)
outletIso$DD13 <- outletIso$d.13C.12C - initialDelta
# Filter isotope data:
filtersIso = read.csv2("Data/MESAlteck_FilterIsotopes.csv", header = T, dec = ".")
#filtersIso <- filtersIso[filtersIso$Levl != "J+7", ]
if (length(filtersIso) == 1){
filtersIso = read.csv("Data/MESAlteck_FilterIsotopes.csv", header = T)
}
colnames(filtersIso)
filtersIso$WeekSubWeek = paste(filtersIso$Week, filtersIso$Num, sep = "-")
colnames(filtersIso)[colnames(filtersIso) == "DD13.32.253."] <- "DD13"
colnames(filtersIso)[colnames(filtersIso) == "ng..C."] <- "ngC"
str(filtersIso)
hydroChem = read.csv2("Data/AO-Hydrochem.csv", header = T)
hydroChem = hydroChem[, c("WeekSubWeek",
"NH4.mM",
"TIC.ppm.filt",
"Cl.mM",
"NO3...mM",
"PO4..mM",
"NPOC.ppm" ,
"TIC.ppm.unfilt",
"TOC.ppm.unfilt" )]
head(hydroChem)
outletIso <- outletIso[complete.cases(outletIso[ , "d.13C.12C"]), ]
isoOutSummary = ddply(outletIso, c("WeekSubWeek"), summarise,
N    = length(d.13C.12C),
diss.d13C = mean(d.13C.12C),
SD.d13C = sd(d.13C.12C),
# se.d13C = SD.d13C / sqrt(N),
N_d13C.diss = length(d.13C.12C))
isoFiltSummary = ddply(filtersIso, c("WeekSubWeek"), summarise,
N    = length(d.13C.12C),
filt.d13C = mean(d.13C.12C),
filt.SD.d13C = sd(d.13C.12C) #,
# filt.se.d13C = filt.SD.d13C / sqrt(N),
# N_ngC.fl = length(ngC),
# ngC.mean.fl = mean(ngC),
# ngC.SD.fl = sd(ngC)
)
head(isoFiltSummary)
View(outletIso)
View(outletConc)
# Dissolved
out.CoIs = merge(outletConc,  outletESAOXA, by = "WeekSubWeek", all = T)
out.CoIs = merge(out.CoIs, isoOutSummary, by = "WeekSubWeek", all = T)
# Filters (MES, Conc.MES)
out.CoIs = merge(out.CoIs, filters, by = "WeekSubWeek", all = T)
out.CoIs = merge(out.CoIs, isoFiltSummary, by= "WeekSubWeek", all = T)
# Remaining fraction
out.CoIs$DD13C.diss <- (out.CoIs$diss.d13C - (d13Co))
out.CoIs$DD13C.filt <- (out.CoIs$filt.d13C - (d13Co))
# Discharge times
out.CoIs = merge(weeklyhydro, out.CoIs, by = "WeekSubWeek", all = T)
# Discharge summary
out.CoIs = merge(weeklyflux, out.CoIs, by = "WeekSubWeek", all = T)
out.CoIs$tf <- as.POSIXct(out.CoIs$tf, "%Y-%m-%d %H:%M", tz = "EST")
out.CoIs$ti <- as.POSIXct(out.CoIs$ti, "%Y-%m-%d %H:%M", tz = "EST")
class(out.CoIs$tf)
sum(is.na(out.CoIs$tf))
View(out.CoIs)
Sys.setlocale("LC_ALL", "English")
library("stringr")
library("plyr")
library("dplyr")
library("zoo")
library("ggplot2")
library("plotly")
# setwd("D:/Documents/these_pablo/Alteckendorf2016/R")
# setwd("/Users/DayTightChunks/Documents/PhD/Routput/Alteck/R")
# setwd("D:/Documents/these_pablo/Alteckendorf2016/00_TransparencyFolder")
getwd()
source("global.R")
weeklyhydro = read.csv2("Data/WeeklyHydro_R.csv", header = TRUE)
colnames(weeklyhydro)[colnames(weeklyhydro) == "ID"] <- "WeekSubWeek"
head(weeklyhydro)
weeklyflux = read.csv2("Data/fluxAlteck2016_R.csv", header = TRUE)
head(weeklyflux)
outletConc = read.csv2("Data/OutletConc_W0toW17.csv", sep = ",", dec =".", header = T)
outletConc$ID4 <- as.character(outletConc$ID4)
outletConc <- outletConc[outletConc$ID4 != "J+7", ]
outletConc$Vol.SPE.L <- outletConc$Vol.SPE.mL/1000
outletConc <- outletConc[,c("WeekSubWeek", "Conc.mug.L", "Conc.SD", "Vol.SPE.L", "Conc.in500uL")]
head(outletConc)
filters = read.csv2("Data/MESAlteckWater.csv")
filters$MO.mg.L = ifelse(filters$MO.mg.L < 0, 0.0001, filters$MO.mg.L)
head(filters)
# MESA/MOXA data cleaning
outletESAOXA = read.csv2("Data/Outlet_ESAOXA_W0toW17.csv", header = T)
outletESAOXA$ID <- as.character(outletESAOXA$ID)
split <- strsplit(outletESAOXA$ID, "-", fixed = TRUE)
outletESAOXA$ESAOXA_SD <- sapply(split, "[", 4)
split_vor <- strsplit(outletESAOXA$ID, "-SD", fixed = TRUE)
outletESAOXA$ESAOXA_Mean <- sapply(split_vor, "[", 1)
means_temp <- subset(outletESAOXA, is.na(outletESAOXA$ESAOXA_SD))
sd_temp <- subset(outletESAOXA, !is.na(outletESAOXA$ESAOXA_SD))
means_temp$ID <- NULL
sd_temp$ID <- NULL
head(sd_temp)
head(means_temp)
outletESAOXA <- merge(means_temp, sd_temp, by = "ESAOXA_Mean", all = T)
outletESAOXA$ESAOXA_SD.x <- NULL
outletESAOXA$ESAOXA_SD.y <- NULL
split_ID <- strsplit(outletESAOXA$ESAOXA_Mean, "A0-", fixed = T)
outletESAOXA$ID <- sapply(split_ID, "[", 2)
outletESAOXA$ESAOXA_Mean <- NULL
outletESAOXA <- outletESAOXA[ , c("ID", "MOXA.ugL.x", "MOXA.ugL.y", "MESA.ugL.x", "MESA.ugL.y")]
colnames(outletESAOXA) <- c("WeekSubWeek", "OXA_mean", "OXA_SD", "ESA_mean",  "ESA_SD")
outletESAOXA$WeekSubWeek <- as.factor(outletESAOXA$WeekSubWeek)
head(outletESAOXA)
# Outlet isotope data:
outletIso = read.csv2("Data/Outlet_Isotopes_W0toW17.csv", header = T, dec = ".")
if (length(outletIso) == 1){
outletIso = read.csv("Data/Outlet_Isotopes_W0toW17.csv", header = T)
}
str(outletIso)
colnames(outletIso)
# Correct for extraction shift
outletIso$d.13C.12C = round( (outletIso$d.13C.12C - meanshift_w), 1)
outletIso$DD13 <- outletIso$d.13C.12C - initialDelta
# Filter isotope data:
filtersIso = read.csv2("Data/MESAlteck_FilterIsotopes.csv", header = T, dec = ".")
#filtersIso <- filtersIso[filtersIso$Levl != "J+7", ]
if (length(filtersIso) == 1){
filtersIso = read.csv("Data/MESAlteck_FilterIsotopes.csv", header = T)
}
colnames(filtersIso)
filtersIso$WeekSubWeek = paste(filtersIso$Week, filtersIso$Num, sep = "-")
colnames(filtersIso)[colnames(filtersIso) == "DD13.32.253."] <- "DD13"
colnames(filtersIso)[colnames(filtersIso) == "ng..C."] <- "ngC"
str(filtersIso)
hydroChem = read.csv2("Data/AO-Hydrochem.csv", header = T)
hydroChem = hydroChem[, c("WeekSubWeek",
"NH4.mM",
"TIC.ppm.filt",
"Cl.mM",
"NO3...mM",
"PO4..mM",
"NPOC.ppm" ,
"TIC.ppm.unfilt",
"TOC.ppm.unfilt" )]
head(hydroChem)
outletIso <- outletIso[complete.cases(outletIso[ , "d.13C.12C"]), ]
isoOutSummary = ddply(outletIso, c("WeekSubWeek"), summarise,
N    = length(d.13C.12C),
diss.d13C = mean(d.13C.12C),
SD.d13C = sd(d.13C.12C),
# se.d13C = SD.d13C / sqrt(N),
N_d13C.diss = length(d.13C.12C))
isoFiltSummary = ddply(filtersIso, c("WeekSubWeek"), summarise,
N    = length(d.13C.12C),
filt.d13C = mean(d.13C.12C),
filt.SD.d13C = sd(d.13C.12C) #,
# filt.se.d13C = filt.SD.d13C / sqrt(N),
# N_ngC.fl = length(ngC),
# ngC.mean.fl = mean(ngC),
# ngC.SD.fl = sd(ngC)
)
head(isoFiltSummary)
# Dissolved
out.CoIs = merge(outletConc,  outletESAOXA, by = "WeekSubWeek", all = T)
out.CoIs = merge(out.CoIs, isoOutSummary, by = "WeekSubWeek", all = T)
# Filters (MES, Conc.MES)
out.CoIs = merge(out.CoIs, filters, by = "WeekSubWeek", all = T)
out.CoIs = merge(out.CoIs, isoFiltSummary, by= "WeekSubWeek", all = T)
# Remaining fraction
out.CoIs$DD13C.diss <- (out.CoIs$diss.d13C - (d13Co))
out.CoIs$DD13C.filt <- (out.CoIs$filt.d13C - (d13Co))
# Discharge times
out.CoIs = merge(weeklyhydro, out.CoIs, by = "WeekSubWeek", all = T)
# Discharge summary
out.CoIs = merge(weeklyflux, out.CoIs, by = "WeekSubWeek", all = T)
out.CoIs$tf <- as.POSIXct(out.CoIs$tf, "%Y-%m-%d %H:%M", tz = "EST")
out.CoIs$ti <- as.POSIXct(out.CoIs$ti, "%Y-%m-%d %H:%M", tz = "EST")
class(out.CoIs$tf)
sum(is.na(out.CoIs$tf))
write.csv(out.CoIs, "Data/MarkerResponse_R05.csv", row.names = F)
# Temprarily remove Weeks 16 & 17 (need to get discharge data)
# No discharge data yet avaialble to multiply against...
out.CoIs <- out.CoIs[!is.na(out.CoIs$tf), ]
# V[m3] * MES [mg/L] * 1000 [L/m3] * [1 Kg/10^6 mg]
out.CoIs$ExpMES.Kg = out.CoIs$Volume.m3*out.CoIs$MES.mg.L/1000
# Assume first index is equivalent to second for all measured values
# (i.e. needed for na.approx operation below)
out.CoIs[1, c("Conc.mug.L")] <- out.CoIs[2, c("Conc.mug.L")]
out.CoIs[1, c("Conc.SD")] <- out.CoIs[2, c("Conc.SD")]
out.CoIs[1, c("Vol.SPE.L")] <- out.CoIs[2, c("Vol.SPE.L")]
out.CoIs[1, c("OXA_mean")] <- out.CoIs[2, c("OXA_mean")]
out.CoIs[1, c("OXA_SD")] <- out.CoIs[2, c("OXA_SD")]
out.CoIs[1, c("ESA_mean")] <- out.CoIs[2, c("ESA_mean")]
out.CoIs[1, c("ESA_SD")] <- out.CoIs[2, c("ESA_SD")]
out.CoIs[1, c("Conc.Solids.mug.gMES")] <- out.CoIs[2, c("Conc.Solids.mug.gMES")]
out.CoIs[1, c("Conc.Solids.ug.gMES.SD")] <- out.CoIs[2, c("Conc.Solids.ug.gMES.SD")]
out.CoIs[1, c("ExpMES.Kg")] <- out.CoIs[2, c("ExpMES.Kg")]
# Assign linear approximation of trailing and leading observed values
out.CoIs <- out.CoIs[with(out.CoIs , order(ti)), ]
out.CoIs$Conc.mug.L <- na.approx(out.CoIs$Conc.mug.L)
out.CoIs$Volume.m3[nrow(out.CoIs)]
val = out.CoIs$Volume.m3[nrow(out.CoIs)]
val
is.na(val)
out.CoIs = out.CoIs[1:nrow(out.CoIs)-1, ]
out.CoIs$Conc.mug.L <- na.approx(out.CoIs$Conc.mug.L)
out.CoIs$Conc.SD <- na.approx(out.CoIs$Conc.SD)
mark = read.csv2(file.path(path, "Data/MarkerResponse_R05.csv"))
View(mark)
mark = read.csv(file.path(path, "Data/MarkerResponse_R05.csv"))
View(q)
q = read.csv2(file.path(path, "Data/groupAlteck2016_R.csv"))
View(q)
names(q)
q = q[ , c("Date", "DateCheck.S", "DateCheck", "Q.HW1", "DayMoYr", "Vol2min", "sampleQ", "Type", "SubWeeks", "Weeks", "WeekNo" )]
q = q[ , c("Date", "DateCheck", "Q.HW1", "DayMoYr", "Vol2min", "sampleQ", "Type", "SubWeeks", "Weeks", "WeekNo" )]
names(mark)
mark = mark[, c("WeekSubWeek", "AveDischarge.m3.h", "Volume.m3",  "Sampled.Hrs", "Sampled", "Conc.mug.L" , "Conc.SD",
"Vol.SPE.L", "Conc.in500uL", "OXA_mean", "OXA_SD", "ESA_mean", "ESA_SD", "N.x", "diss.d13C", "SD.d13C",
"N_d13C.diss", "MES.mg.L", "MES.sd", "MO.mg.L", "Conc.Solids.mug.gMES", "Conc.Solids.ug.gMES.SD", "N.y",
"filt.d13C",  "filt.SD.d13C", "DD13C.diss", "DD13C.filt" )]
names(mark)
mark = mark[, c("WeekSubWeek", "AveDischarge.m3.h", "Volume.m3",  "Sampled.Hrs", "Sampled", "Conc.mug.L" , "Conc.SD",
"Vol.SPE.L", "Conc.in500uL", "OXA_mean", "OXA_SD", "ESA_mean", "ESA_SD", "N.x", "diss.d13C", "SD.d13C",
"MES.mg.L", "MES.sd", "MO.mg.L", "Conc.Solids.mug.gMES", "Conc.Solids.ug.gMES.SD", "N.y",
"filt.d13C",  "filt.SD.d13C", "DD13C.diss", "DD13C.filt" )]
names(mark)
mark = mark[, c("WeekSubWeek",
# "AveDischarge.m3.h", "Volume.m3",  "Sampled.Hrs",
"Sampled", "Conc.mug.L" , "Conc.SD",
"Vol.SPE.L", "Conc.in500uL", "OXA_mean", "OXA_SD", "ESA_mean", "ESA_SD", "N.x", "diss.d13C", "SD.d13C",
"MES.mg.L", "MES.sd", "MO.mg.L", "Conc.Solids.mug.gMES", "Conc.Solids.ug.gMES.SD", "N.y",
"filt.d13C",  "filt.SD.d13C", "DD13C.diss", "DD13C.filt" )]
names(mark)
mark = mark[, c("WeekSubWeek",
# "AveDischarge.m3.h", "Volume.m3",  "Sampled.Hrs",
"Sampled",
"Conc.mug.L" , "Conc.SD",
# "Vol.SPE.L", "Conc.in500uL",
"OXA_mean", "OXA_SD", "ESA_mean", "ESA_SD",
"N.x", "diss.d13C", "SD.d13C",
"MES.mg.L", "MES.sd", "MO.mg.L", "Conc.Solids.mug.gMES", "Conc.Solids.ug.gMES.SD",
"N.y",  "filt.d13C",  "filt.SD.d13C" #,
#"DD13C.diss", "DD13C.filt"
)]
mark$WeekSubWeek[nrow(mark)-1]
mark$WeekSubWeek[nrow(mark)-1]
mark$WeekSubWeek[nrow(mark)-1] == as.factor("W6-3j7")
mark$WeekSubWeek[nrow(mark)-1] == as.character("W6-3j7")
mark = mark[mark$WeekSubWeek != as.character("W6-3j7")]
mark = mark[mark$WeekSubWeek != as.character("W6-3j7"), ]
mark = mark[mark$WeekSubWeek != as.character("W6-3j7") & !is.na(mark$WeekSubWeek), ]
mark = mark[, c("WeekSubWeek",
# "AveDischarge.m3.h", "Volume.m3",  "Sampled.Hrs",
# "Sampled",
"Conc.mug.L" , "Conc.SD",
# "Vol.SPE.L", "Conc.in500uL",
"OXA_mean", "OXA_SD", "ESA_mean", "ESA_SD",
"N.x", "diss.d13C", "SD.d13C",
"MES.mg.L", "MES.sd", "MO.mg.L", "Conc.Solids.mug.gMES", "Conc.Solids.ug.gMES.SD",
"N.y",  "filt.d13C",  "filt.SD.d13C" #,
#"DD13C.diss", "DD13C.filt"
)]
q$Date = as.POSIXct(strptime(q$DateCheck, "%d/%m/%Y %H:%M", tz="EST"))
q$DayMoYr = as.POSIXct(strptime(q$DateCheck, "%d/%m/%Y", tz="EST"))
sum(is.na(q$Date))
naDates = q[is.na(q$Date == TRUE),]
duplicateAlteck <- q[duplicated(q$DateCheck),]
head(duplicateAlteck)
catchment_area
